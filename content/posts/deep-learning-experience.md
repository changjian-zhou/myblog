---
title: "Deep Learning 调参经验"
date: 2024-10-14T18:30:13+08:00
draft: false
tags:
  - Deep Learning
---

> 调参是锦上添花的事，而底线取决于：模型的选择和数据的清洗。

模型最后的性能如何应该主要取决于以下四点：
1. 数据集
2. 模型
3. 损失函数和优化器
4. 模型的训练与测试

## 数据集
- 数据量太多时，先用少量（1/10 or 1/100）的数据去跑，估算训练时间
- 视觉一定要使用数据增强
- 数据一定要进行预处理
- 数据输入时，观察数据质量;模型训练结束后，观察bad case

## 模型
- 尽量不要自己手写模型，找一个没有bug或者已经走通的模型自己去修改。
- 数据量太小时，找预训练模型去微调
- RELU、Sigmoid、Softmax、Tanh，常用的激活函数
- 输出层用sigmoid与softmax,中间层用RELU,RNN用Tanh
- Dropout与BN非常好用

## 损失函数与优化器
- Lr与Batch size相互影响，互相成正比
- Lr有很多trick,如指数下降
- 观察loss曲线，及时early stopping
- Adam快速收敛，SGDM精度高（如果非要二选一，Adam）

## 训练与测试
- 参数初始化方法，首先为预训练，其次为Xavir
- 训练loss低，但测试loss高，模型泛化能力不行
- 每次调参只改一个参数
- 在验证时，可设置某规则以使模型向想要的方向更新

